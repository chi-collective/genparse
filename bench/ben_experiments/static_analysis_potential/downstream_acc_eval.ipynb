{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bench.spider.schema import load_schemas\n",
    "from bench.spider.dialogue import load_spider_data\n",
    "from bench.spider.prompt_formatter import SpiderPromptFormatter\n",
    "\n",
    "raw_spider_dir = Path('../../spider/data/spider')\n",
    "\n",
    "train_data = load_spider_data(\n",
    "    raw_spider_dir / 'train_spider.json'\n",
    ")\n",
    "\n",
    "dev_data = load_spider_data(\n",
    "    raw_spider_dir / 'dev.json'\n",
    ")\n",
    "\n",
    "spider_schemas = load_schemas(\n",
    "    schemas_path=raw_spider_dir / 'tables.json', \n",
    "    db_path=raw_spider_dir / 'database'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from evaluation_utils import get_final_particles_from_record, create_particle_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_name = 'table_column_potential_n_particles_50'\n",
    "\n",
    "results = []\n",
    "with open(results_name + '.jsonl', 'r') as f:\n",
    "    for l in f:\n",
    "        results.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 901/1034 [31:18<06:39,  3.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [37:30<00:00,  2.18s/it]\n",
      " 68%|██████▊   | 705/1034 [38:39<07:40,  1.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 819/1034 [42:05<11:29,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 820/1034 [42:30<34:57,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 824/1034 [42:40<15:35,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 826/1034 [42:42<10:07,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 827/1034 [42:58<23:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 846/1034 [44:04<14:29,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n",
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 849/1034 [44:25<19:28,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 858/1034 [44:42<05:07,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 859/1034 [45:48<1:01:19, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query execution timed out after 10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1034/1034 [52:29<00:00,  3.05s/it] \n",
      "100%|██████████| 1034/1034 [54:52<00:00,  3.18s/it] \n",
      "100%|██████████| 1034/1034 [1:03:22<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from evaluation_utils import run_and_add_evaluation\n",
    "\n",
    "results = run_and_add_evaluation(\n",
    "    results, \n",
    "    raw_spider_dir=raw_spider_dir, \n",
    "    n_workers=8, \n",
    "    overwrite=False, \n",
    "    timeout=10\n",
    ")\n",
    "\n",
    "with open(results_name + '-evaluated' + '.jsonl', 'w') as f:\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results_name = 'table_column_potential_n_particles_5-evaluated'\n",
    "\n",
    "results = []\n",
    "with open(results_name + '.jsonl', 'r') as f:\n",
    "    for l in f:\n",
    "        results.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bench.spider.schema import load_schemas\n",
    "from run_inference import table_column_potential\n",
    "\n",
    "raw_spider_dir = Path('../../spider/data/spider')\n",
    "spider_schemas = load_schemas(\n",
    "    schemas_path=raw_spider_dir / 'tables.json', \n",
    "    db_path=raw_spider_dir / 'database'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def make_df(new_results):\n",
    "\n",
    "    df_lines = []\n",
    "    for i, result in tqdm(enumerate(new_results)):        \n",
    "        df_lines.append({\n",
    "            'question': result['question'],\n",
    "            'ess_threshold': result['ess_threshold'] if 'ess_threshold' in result else 0,\n",
    "            'n_particles': result['n_particles'],\n",
    "            'method': result['method'],\n",
    "            'result': result['results']['posterior_weighted_acc']['result'],\n",
    "            'n_replicate': result['n_replicate'],\n",
    "            'instance_idx': i,\n",
    "            'resample_method': result['resample_method'] if 'resample_method' in result else 'multinomial',\n",
    "        })\n",
    "\n",
    "        if result['method'] == 'sis_no_potential':\n",
    "            particle_results = result['results']['posterior_weighted_acc']['particle_results']\n",
    "\n",
    "            assert result['n_particles'] == len(particle_results)\n",
    "\n",
    "            acc = 0\n",
    "            for particle_result in particle_results:\n",
    "                if particle_result[1][0]:\n",
    "                    acc += 1\n",
    "\n",
    "            acc = acc / result['n_particles']\n",
    "\n",
    "            df_lines.append({\n",
    "                'question': result['question'],\n",
    "                'ess_threshold': result['ess_threshold'] if 'ess_threshold' in result else 0,\n",
    "                'n_particles': result['n_particles'],\n",
    "                'method': 'local_poe',\n",
    "                'result': acc,\n",
    "                'n_replicate': result['n_replicate'],\n",
    "                'instance_idx': i,\n",
    "                'resample_method': 'multinomial',\n",
    "            })\n",
    "\n",
    "        if result['method'] == 'sis':\n",
    "            particle_results = result['results']['posterior_weighted_acc']['particle_results']\n",
    "\n",
    "            assert result['n_particles'] == len(particle_results)\n",
    "\n",
    "            particles = get_final_particles_from_record(result['record'])\n",
    "\n",
    "            # Renormalize distribtion based on potential results.\n",
    "            # Because we are log_eps as the value for invalid cases,\n",
    "            # we cannot systematically recover the potential values\n",
    "            # from the weights. \n",
    "\n",
    "            potential_values = table_column_potential(\n",
    "                particles=create_particle_approx(particles), \n",
    "                schema_name=result['db_name'], \n",
    "                grammar_path='../spider_grammars',\n",
    "                spider_schemas=spider_schemas\n",
    "            )\n",
    "\n",
    "            acc = 0\n",
    "            n_valid = 0\n",
    "            for i, particle_result in enumerate(particle_results):\n",
    "                assert ''.join(particle_result[0]) == ''.join(particles[i]['context'])\n",
    "                if potential_values[i] == 0:  \n",
    "                #if particles[i]['weight'] > np.log(1e-10):\n",
    "                    n_valid += 1\n",
    "                    if particle_result[1][0]:\n",
    "                        acc += 1\n",
    "\n",
    "            acc = acc / n_valid if n_valid > 0 else 0\n",
    "\n",
    "            df_lines.append({\n",
    "                'question': result['question'],\n",
    "                'ess_threshold': result['ess_threshold'] if 'ess_threshold' in result else 0,\n",
    "                'n_particles': result['n_particles'],\n",
    "                'method': 'local_poe_with_potential',\n",
    "                'result': acc,\n",
    "                'num_resample_steps': 0,\n",
    "                'n_replicate': result['n_replicate'],\n",
    "                'instance_idx': i,\n",
    "                'resample_method': 'multinomial',\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(df_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6069843c63034f8bafa1add70929deb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th>n_particles</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lm_baseline</th>\n",
       "      <th>50</th>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.364068</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_poe</th>\n",
       "      <th>50</th>\n",
       "      <td>0.564391</td>\n",
       "      <td>0.366432</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_poe_with_potential</th>\n",
       "      <th>50</th>\n",
       "      <td>0.598549</td>\n",
       "      <td>0.363924</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sis</th>\n",
       "      <th>50</th>\n",
       "      <td>0.625974</td>\n",
       "      <td>0.368413</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sis_no_potential</th>\n",
       "      <th>50</th>\n",
       "      <td>0.603244</td>\n",
       "      <td>0.370643</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smc</th>\n",
       "      <th>50</th>\n",
       "      <td>0.621714</td>\n",
       "      <td>0.377360</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smc_no_potential</th>\n",
       "      <th>50</th>\n",
       "      <td>0.598601</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        result                \n",
       "                                          mean       std  size\n",
       "method                   n_particles                          \n",
       "lm_baseline              50           0.538356  0.364068  1034\n",
       "local_poe                50           0.564391  0.366432  1034\n",
       "local_poe_with_potential 50           0.598549  0.363924  1034\n",
       "sis                      50           0.625974  0.368413  1034\n",
       "sis_no_potential         50           0.603244  0.370643  1034\n",
       "smc                      50           0.621714  0.377360  1034\n",
       "smc_no_potential         50           0.598601  0.376286  1034"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_df(results)\n",
    "df.groupby(['method', 'n_particles']).agg({'result': ['mean', 'std', 'size']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('table_column_potential_n_particles50_llama3.1-8B-instruct_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
