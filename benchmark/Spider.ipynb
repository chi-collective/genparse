{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f44124-d539-459d-92a5-e908cb9929e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38267b-c1c5-4cc4-bbb6-5ffbd6eff7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arsenal import colors\n",
    "from bench.spider.interface import SpiderInterface\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762eb64-e9a2-41c7-ab09-b3ff3c5fb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "spider = SpiderInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b211006-7d05-495b-8e45-c53b015f0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in spider.dev_data[:2]:\n",
    "    print()\n",
    "    print(x.text)\n",
    "    print(x.gold_sql)\n",
    "    print(x.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99c672-c9f6-46bc-a425-ad5dbb6f0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spider.dev_data[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea4e95-286a-4f52-af9c-2a76a158ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.evaluate(x.gold_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd72b7-ae8e-4eca-a124-6bd2582c6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spider.dev_data[1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9609f9d-92dc-4ffa-86d1-ecb847370d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.evaluate('SELECT count(*) FROM singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa38854",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.run_query('SELECT count(*) FROM singer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11484f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709a74e-e1fd-4239-ac4b-206f953ded3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import bench.spider.evaluation as E\n",
    "from bench.spider.evaluation import (\n",
    "    #build_foreign_key_map_from_json,\n",
    "    build_valid_col_units,\n",
    "    rebuild_sql_val,\n",
    "    rebuild_sql_col,\n",
    "    eval_exec_match,\n",
    ")\n",
    "\n",
    "def evaluate(self, gold: str, pred: str, db_name: str):\n",
    "    \"\"\"Returns: bool, Optional[str]\n",
    "\n",
    "    On success (i.e., predicted execution result is the same as gold), returns `(True, None)`\n",
    "    On failure, returns `(False, reason)` where reason is one of the two cases:\n",
    "    * `invalid` if `pred` sql is not a well-formed sql statement that can be parsed by sqlite\n",
    "    * `mismatch` if `pred` is a well-formed sql but the execution result is different from that of the `gold`.\n",
    "    \"\"\"\n",
    "    db = self.db_path / db_name / (db_name + '.sqlite')\n",
    "    schema = E.Schema(E.get_schema(db))\n",
    "    g_sql = E.get_sql(schema, gold)\n",
    "\n",
    "    try:\n",
    "        p_sql = E.get_sql(schema, pred)\n",
    "    except Exception as e:\n",
    "        # sql is ill-formed (can't be parsed by sqlite engine)\n",
    "        print(colors.red % e.__class__.__name__, e, )\n",
    "\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return False, 'invalid'\n",
    "\n",
    "    kmap = self.kmaps[db_name]\n",
    "    g_valid_col_units = build_valid_col_units(g_sql['from']['table_units'], schema)\n",
    "    g_sql = rebuild_sql_val(g_sql)\n",
    "    g_sql = rebuild_sql_col(g_valid_col_units, g_sql, kmap)\n",
    "    p_valid_col_units = build_valid_col_units(p_sql['from']['table_units'], schema)\n",
    "    p_sql = rebuild_sql_val(p_sql)\n",
    "    p_sql = rebuild_sql_col(p_valid_col_units, p_sql, kmap)\n",
    "\n",
    "    exec_match = eval_exec_match(db, pred, gold, p_sql, g_sql)\n",
    "    reason = None if exec_match else 'mismatch'\n",
    "\n",
    "    return exec_match, reason\n",
    "\n",
    "#spider.evaluator = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2044d38-ed05-4bf9-8294-69a0f8388a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.interface.evaluator = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff725aa3-aadc-49c0-af86-7e4e68b95c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.interface.evaluator.evaluate = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb85928-d061-4c6f-a6f1-07a60fd55272",
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_sql = 'select count(*) from singer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8e0bd-ba11-4f73-9d0c-306be55d3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.interface.evaluator.evaluate(x.interface.evaluator, gold = x.gold_sql, pred = junk_sql, db_name = x.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdf70d-7695-4506-a049-bb7f5297de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.db_schema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08428768",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_text = open('/home/timv/projects/genparse/benchmark/grammars/sql_case_insensitive.lark').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genparse.util import InferenceSetupVLLM, InferenceSetup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infer = InferenceSetup('codellama', grammar_text, proposal_name='character', guide_opts={'ignore': '\\s*'})\n",
    "infer = InferenceSetupVLLM('codellama', grammar_text, proposal_name='character', guide_opts={'ignore': r'\\s*'}, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1387a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer.sampler.llm._model.batch_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e98350",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = infer(x.describe(), n_particles=50, method='smc-standard', max_tokens=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca12ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91570990",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spider.dev_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y, py in sorted(p[0].posterior.items(), key=lambda ab: -ab[1]):\n",
    "    y = y[:-1]  # remove EOS\n",
    "    print(f'{colors.mark(x.evaluate(y))} {py:-.6f} {y}')\n",
    "    try:\n",
    "        display(x.run_query(y))\n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(colors.dark.red % 'ðŸ’€ ERROR', e)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad14041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
