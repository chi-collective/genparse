{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f7044-7797-46ab-a98e-e36962f9ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genparse.lm import TokenGPT2\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from genparse import CFGLM\n",
    "from genparse.steer import LocalProduct\n",
    "from arsenal.maths import softmax, sample\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2dc0bf-756a-4efc-989e-230961113829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizingLM:\n",
    "\n",
    "    def __init__(self, tokenizer, model):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.model(self.tokenizer.encode(x))\n",
    "\n",
    "    def p_next(self, x):\n",
    "        # warning: misalignment is might occur here!\n",
    "        p = self.model.p_next(self.tokenizer.encode(x))\n",
    "\n",
    "        assert len(p) == self.tokenizer.vocab_size\n",
    "        s = [self.tokenizer.decode([k]) for k in range(len(p))]\n",
    "\n",
    "        # XXX: apparently, multiple tokens in the mapping (token -> substring)\n",
    "        # can point to the same substring!\n",
    "        P = Counter()\n",
    "        for k in range(len(p)):\n",
    "            P[s[k]] += p[k].item()\n",
    "\n",
    "        return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7bef5-4173-4ead-92ab-819ff5045317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbac34-a10d-4004-9968-3a16eb34dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5fe9a-121f-4a10-a6b9-e87a56fda169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fdb8aaa-8a8c-4f24-a772-111c6ecad167",
   "metadata": {},
   "source": [
    "Note that the tokenizer might have multiple tokens that map to the same string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b074a8-3409-4f00-8e87-2cc5da2803a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(tokenizer.decode([k]) for k in range(tokenizer.vocab_size)).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d29ca-b8ed-43b9-bd51-f4a4e15aa800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0efa3-b6e5-416c-9b99-4de01f18f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = TokenGPT2(gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55478f1-91c3-4cfa-b874-321165ca8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1dd70-f983-4bae-930f-d955ce4a5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.p_next([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc295b-b212-443f-b8ec-0d4a351fd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.p_next([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b9174-a20b-4887-929e-c28390fd3990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bf971-2628-4a4a-8bfc-d417000fce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = TokenizingLM(tokenizer, lm).p_next('Once upon a time,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90506e8-44c8-4b16-806f-92d7c9a95f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = TokenizingLM(tokenizer, lm).p_next('The following is some code that implements quick sort in Python:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a0edd-b4de-4899-a72e-3c9cac8ea17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(p.items()).set_index(0).sort_values(1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ef417-d1ca-4aab-bf59-f6e3a5a7f386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472a36b-25aa-4f54-a450-a7b9ffe272c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f77f2-3f34-4278-9069-f1c137ad24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = TokenizingLM(tokenizer, lm)\n",
    "#.p_terminal('The following is some code that implements quick sort in Python:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98527f-4397-433e-8c12-ad7aab79df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, xs):\n",
    "        self.xs = xs\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, Particle) and self.xs == other.xs\n",
    "    def __hash__(self):\n",
    "        return hash(self.xs)\n",
    "    def __repr__(self):\n",
    "        return f'{self.xs}'\n",
    "    def p(self):\n",
    "        P = M.p_next(self.xs)\n",
    "        return Particles({Particle(self.xs + x): w for x, w in P.items()})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bb1fc-3a60-45ee-ab56-67fc76251f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particles(dict):\n",
    "    def __repr__(self):\n",
    "        return repr(Counter(self).most_common(10))\n",
    "    def sample(self):\n",
    "        ks, ws = np.array(list(self.keys())), np.array(list(self.values()))        \n",
    "        #ws[np.argsort(-ws)[50:]] = 0\n",
    "#        return ks[sample(softmax(ws))]\n",
    "        return ks[sample(ws)]\n",
    "    def greedy(self):\n",
    "        ks, ws = list(self.keys()), np.array(list(self.values()))\n",
    "        return ks[ws.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab553a-d1d7-4ca7-a369-e2bda044367a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a1d60-4184-47f9-9ac3-8a04a8bea8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Particle('The following is some code that implements the quick sort algorithm in Python:')\\\n",
    ".p().sample().p().sample().p().sample().p().sample().p().sample().p().sample().p().sample()\\\n",
    ".p().sample().p().sample().p().sample().p().sample().p().sample().p().sample().p().sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fffc5c-6d0a-477b-85d3-518dcea6edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Particle('Once upon a time')\\\n",
    ".p().sample().p().sample().p().sample().p().sample().p().sample().p().sample().p().sample()\\\n",
    ".p().sample().p().sample().p().sample().p().sample().p().sample().p().sample().p().sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccd3c4-405c-4f1b-b4b3-f7eecf4b80d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6b2da-ecaf-4dba-a8ab-9c5ce0b428c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Particle('Once upon a time,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca1245-818e-44cb-9bcc-a20362c4a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f58a29-2cf3-49b2-8abb-b3353190a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.p().sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00573763-8e4c-43d5-ab26-a3d1a07ba0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p.p().greedy().p().greedy().p().greedy().p().greedy().p().greedy().p().greedy()\n",
    " .p().greedy().p().greedy().p().greedy().p().greedy().p().greedy().p().greedy()\n",
    "# .p().greedy().p().greedy().p().greedy().p().greedy().p().greedy().p().greedy()\n",
    "# .p().greedy().p().greedy().p().greedy().p().greedy().p().greedy().p().greedy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564a9d2-6a4e-4626-88d9-fc025436b677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec332a04-ee19-440a-9294-bbd360775a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
