{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d8769c-975b-4ca8-a4ba-5d7ca9dec447",
   "metadata": {},
   "source": [
    "# Token Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fb828-28ae-4f5f-8fb7-214f325dfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988df6c8-bbb1-4a56-96c0-50ed95639b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genparse import CFGLM\n",
    "from genparse.cfglm import locally_normalize, EOS\n",
    "from genparse.align import CharAlignedCFGLM\n",
    "from genparse.util import display_table\n",
    "from genparse.steer import generation_tree\n",
    "from genparse.segmentation import bpe_wfst, segmentation_pfst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a49ab-c6c7-4a4c-a903-399b761dde55",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\aa}[0]{\\boldsymbol{a}}\n",
    "\\newcommand{\\bb}[0]{\\boldsymbol{b}}\n",
    "\\newcommand{\\AA}[0]{\\mathcal{A}}\n",
    "\\newcommand{\\BB}[0]{\\mathcal{B}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b8df3-b2cd-4f95-813d-10a7949609ec",
   "metadata": {},
   "source": [
    "Let $p$ be a distribution over character strings $\\aa \\in \\AA^*$.\n",
    "\n",
    "Let $p'$ be a distribution over BPE strings $\\bb \\in \\BB^*$.\n",
    "\n",
    "Let $\\phi\\colon \\BB^* \\to \\AA^*$ be a decoding function. The decoding function satisfies: $\\phi(\\bb \\, \\bb') = \\phi(\\bb) \\, \\phi(\\bb')$ for all $\\bb, \\bb' \\in \\BB^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78971f03-773c-43dd-90fe-900cb64b269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = CFGLM.from_string(\n",
    "    \"\"\"\n",
    "\n",
    "1: S -> a\n",
    "1: S -> a a\n",
    "2: S -> a a a\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "A = p.cfg.V\n",
    "B = {'a', 'aa', 'aaa', EOS}\n",
    "ϕ = lambda b: ''.join(b).strip(EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ecf78-e7a2-48c9-97ff-65b8ba53aee8",
   "metadata": {},
   "source": [
    "Our goal is to transform the distribution $p$ into a distribution $p'$ such that the following correctness condition holds:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61bb15-f17e-44b5-8463-5ec6c3f2b928",
   "metadata": {},
   "source": [
    "**Correctness Condition:**\n",
    "\n",
    "$$\n",
    "\\forall \\aa \\in \\AA\\colon\\quad   p(\\aa) = \\sum_{\\bb\\colon\\ \\phi(\\bb) = \\aa} p'(\\bb)\n",
    "$$\n",
    "\n",
    "The correctness condition ensures that the process: $\\bb \\sim p'$, $\\aa = \\phi(\\bb)$ generates $\\aa$ that is distributed $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8a969-ad7d-4710-b444-3a62adf4e566",
   "metadata": {},
   "source": [
    "**A stochastic tokenization model:**\n",
    "\n",
    "$$\n",
    "p'(\\bb) = \\sum_{\\aa} \\, p(\\aa) \\, \\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\underbrace{p(\\bb \\mid \\aa)}_{\\substack{\\text{probabilistic transducer} \\\\ \\text{where } \\phi(\\bb) = \\aa \\text{ holds } w.p.1 }}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe5208-c836-41a4-a8dc-00c4bcf2abae",
   "metadata": {},
   "source": [
    "When $p$ is PCFG-LMs, we may use composition with any segmentation PFST to construction $p'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e61ce9-dedf-4087-9e6d-44ed42aaa21e",
   "metadata": {},
   "source": [
    "**Tokenization Preferences.**\n",
    "It is possible to satisfy the correctness conditions in undesirable ways because they would adversely affect the downstream components.\n",
    "Consider the following **unwanted workaround** for BPE tokenization.  In that case, we have, by construction, individual characters included in the token vocabulary.  This means we can define a trivial segmentation that only takes unit-length segments as the only tokenization with nonzero probability.  This will not be the preferred prediction scheme of the LLM model, as it will generally prefer the segments that are more representative of those appearing in this context in the training data.  These tend to be the longest-matching tokens.  Some LMs are trained with subword-regularization schemes, which may make them more robust to the specific segmentation.  These are design choices, we suggested that relatively flat distributions over segmentations will likely work best.  However, the maximum-match version has computational benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad45f13-4cd1-4a49-b614-e8a3baf75176",
   "metadata": {},
   "source": [
    "### Grafting Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f6a65-21da-45db-9329-85d4c48dd8c0",
   "metadata": {},
   "source": [
    "Below, we explore some preliminary attempts to understand the distortion in the char-alignment adaptor (I might refer to this as \"grafting\" or a more global transduction-based approach)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837c2bf-6b1e-47c8-9731-4e5412de2071",
   "metadata": {},
   "source": [
    "The class `CharAlignedCFGLM` implements an LM $q$ over tokens based on the following conditional factorization:\n",
    "\n",
    "$$\n",
    "q(b_{N+1} \\mid b_1, \\ldots, b_N) \\propto p( a_{N+1} \\mid a_1 \\cdots a_N )\n",
    "$$\n",
    "\n",
    "where $b_1, \\ldots, b_N$ are a sequence of tokens ids, and $a_1, \\ldots, a_N$ are their respective strings in $\\mathcal{A}^*$ (i.e., $\\phi(b_k) = a_k$ for each $k = 1, \\ldots, N$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8659235-6e35-47f7-bc2e-082e7dab9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "graft = CharAlignedCFGLM(p, B, EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fba5c-a6e1-4461-8d31-d14dc71dbafd",
   "metadata": {},
   "source": [
    "Our target distribution is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5c923-ef64-49f1-9201-5ee2c1ea2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_tree(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3feb0-a61c-4b37-983b-2027c63aad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_tree(graft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac6fe7-45f6-436f-b66a-d7eee974e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_tree(graft, chunked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc1f06-d095-4c28-8060-2ccef0ce862f",
   "metadata": {},
   "source": [
    "### Weighted Transducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3963cbc2-4f8d-4ce1-99de-2afddf25361b",
   "metadata": {},
   "source": [
    "The following WFST simulates the BPE's desire to create chunks from character sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26923635-68fe-4390-8f87-690ca184a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = bpe_wfst((b, tuple(b)) for b in B).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56323c4-8648-493e-801c-016e42198618",
   "metadata": {},
   "source": [
    "We can push some specific character strings throught the transducer to see all of the ways that can be chunked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231ba0e-162e-44b7-ae18-22104a176b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T('aaa', None).epsremove.trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c1f6b-ecee-465c-893b-facf6f72fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "T('aaa', None).total_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba45118-21aa-4b82-bc56-552d19bdd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_lm = CFGLM(locally_normalize((p.cfg @ T).trim(), tol=1e-100).trim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e9331-76e1-414e-943b-f59a1452bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = b_lm.cfg.language(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60fba6-01a0-49e7-b1fa-2802482f8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_tree(b_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7eee2-4785-4000-b3de-53a592661d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL = L.project(ϕ)\n",
    "PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25465c7e-124f-4fbd-a33a-6da3db9ee1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(\n",
    "    [[p.cfg.language(100).project(ϕ), generation_tree(graft).D, PL]],\n",
    "    headings=['target', 'grafting-heuristic', 'composition'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd38460-3666-42de-ab45-390ceb9e4cf2",
   "metadata": {},
   "source": [
    "### The Probabilistic Segmentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4cae-e614-441e-ad78-eb9420c3633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT = segmentation_pfst(B, p.cfg.V - {EOS}, canonical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7c391-d3e5-4367-b506-77301fbe8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d114a-052e-4fdc-8822-f0bbac075174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pb_lm = CFGLM(locally_normalize((p.cfg @ PT).trim()).trim())\n",
    "pb_lm = CFGLM((p.cfg @ PT).trim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70360598-6fbe-42a0-b4e8-338658071c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_tree(pb_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b932d-8308-41f9-90eb-bea367b68d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_PB = pb_lm.cfg.language(100).project(ϕ)\n",
    "L_PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585c59e-7806-46e6-b269-d92d3fff8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_PB.assert_equal(p.cfg.language(100).project(ϕ))  # character-level distribution matches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bb7af-c7b3-4075-8fd9-28dfcb60369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(\n",
    "    [[p.cfg.language(100).project(ϕ), L_PB, generation_tree(graft).D, PL]],\n",
    "    headings=['target', 'pfst', 'grafting-heuristic', 'composition'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ab15a-20d9-4e3c-bfdc-1fb77c973307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
