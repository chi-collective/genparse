{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d8769c-975b-4ca8-a4ba-5d7ca9dec447",
   "metadata": {},
   "source": [
    "# Exploring FSTs for Token Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fb828-28ae-4f5f-8fb7-214f325dfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988df6c8-bbb1-4a56-96c0-50ed95639b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arsenal import timeit\n",
    "from IPython.display import HTML\n",
    "from genparse import FST, Float, EarleyLM as CFGLM, MockLLM, locally_normalize, EOS\n",
    "from genparse.proposal import TokenProposal\n",
    "from genparse.util import LarkStuff, interegular_to_wfsa\n",
    "from genparse.trace import TraceSWOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00488d5-1f85-482d-a716-e221d51e3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe2term_approx(tokenizer, bpe_sequence):\n",
    "    from genparse import FST, Float\n",
    "\n",
    "    # approximate the transducer using a single canonical path;\n",
    "    # UPDATE: the unpruned answer should match this - it's the uncertainty over bpe that's tricky\n",
    "    c = tuple(\n",
    "        ([b], tokenizer.convert_ids_to_tokens(b).replace('Ġ', ' ')) for b in bpe_sequence\n",
    "    )\n",
    "    tmp = FST.from_pairs([([], '')], Float)\n",
    "    for pair in c:\n",
    "        tmp = tmp * FST.from_pairs([pair], Float)\n",
    "    return tmp\n",
    "    # TODO: approximate this transducer by a canonical path\n",
    "    # return c2t(c, None).trim.epsremove.trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdb399-bb2d-4743-99cc-2e2ee54b4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was a method on LarkStuff\n",
    "def lark_stuff_transducer(self, decay=0.99):\n",
    "    from genparse import EPSILON, FST, Float\n",
    "\n",
    "    m = FST(Float)\n",
    "    START = 0\n",
    "    STOP = 1\n",
    "    m.add_I(START, 1)\n",
    "    m.add_F(STOP, decay)\n",
    "    m.add_arc(STOP, (EPSILON, EPSILON), START, 1)\n",
    "    for token_id, token_class in enumerate(self.terminals):\n",
    "        fsm = interegular_to_wfsa(token_class.pattern.to_regexp())\n",
    "        for i, w in fsm.I:\n",
    "            m.add_arc(START, (EPSILON, token_class.name), (token_id, i), w)\n",
    "        for i, w in fsm.F:\n",
    "            m.add_arc((token_id, i), (EPSILON, EPSILON), STOP, w)\n",
    "        for state in fsm.states:\n",
    "            for char, next_state, w in fsm.arcs(state):\n",
    "                m.add_arc(\n",
    "                    (token_id, state),\n",
    "                    (char, EPSILON),\n",
    "                    (token_id, next_state),\n",
    "                    w * decay,\n",
    "                )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896cdb0-2de9-4437-bb3e-e1ea804ee184",
   "metadata": {},
   "source": [
    "## Accounting for BPE's Tokenization Ambiguity with Transduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e285f-399d-48d1-bc66-2739a1398289",
   "metadata": {},
   "outputs": [],
   "source": [
    "lark_stuff = LarkStuff(\n",
    "    r\"\"\"\n",
    "    start: NAME\n",
    "    NAME: /(a|b)*c/\n",
    "    \"\"\"\n",
    ")\n",
    "foo = lark_stuff.char_cfg()\n",
    "foo = locally_normalize(foo)\n",
    "assert len(foo.trim()) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b890e-af73-4986-8a7c-505834886378",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6210c0-59f6-452b-99c7-a0cb33b7df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.cnf.language(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a198bd4-ab33-429b-a5c8-46487410a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = CFGLM(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae3d3c-02d9-47f7-a025-0c934c42c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = TraceSWOR()\n",
    "for t in range(15):\n",
    "    with trace:\n",
    "        print(t, lm.sample(draw=trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08f4a7-5d7a-458c-8cbe-95f33276801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def about(m):\n",
    "    print(len(m.states), 'states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d5323-1d77-4d45-b510-c0c02a2e2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from genparse.tokenization import decode_tokenizer_vocab\n",
    "from genparse.segmentation import bpe_wfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46c45e-00c4-4d81-93a4-875c042bc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "decode = decode_tokenizer_vocab(tokenizer)\n",
    "T = bpe_wfst(enumerate(decode))\n",
    "about(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7dea7-788c-4002-bac9-7f7249852acb",
   "metadata": {},
   "source": [
    "Let's shrink the BPE transducer down to something managable by limiting it alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f862e-9096-4ede-ba35-c632bdf2a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b2c = T.prune_to_alphabet(None, foo.V | {''}).renumber\n",
    "# about(b2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba0052-1e7c-479a-9ff7-d0b3b3d20921",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c = T.prune_to_alphabet(None, foo.V | {''}).renumber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b03ac6d-e5bd-4b66-8516-5b01eb56e7b5",
   "metadata": {},
   "source": [
    "We can look at our little language's strings thru the lense of their possible BPE sequences.  Notice that these strings are ambiguously mapped to BPE --- meaning that there are many BPE sequences that would give rise to the same string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63583038-d333-48a6-8e53-4403df9b9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in foo.cnf.language(3):\n",
    "    display(HTML('<hr/>'))\n",
    "    print(x)\n",
    "    bpe_x = b2c(None, x).epsremove.trim\n",
    "    print('total weight of BPE sequences (i.e., ambiguity):', bpe_x.total_weight())\n",
    "    display(bpe_x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01e546-c37e-46f8-900e-de303dce77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = (b2c @ foo).trim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749db69-bb67-471c-9af3-db09a4b2e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebec9fe-55b0-4b08-9c5d-20e123115fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Float.chart()\n",
    "for (\n",
    "    x,\n",
    "    w,\n",
    ") in tmp.cnf.language(5).items():\n",
    "    y = tokenizer.decode(x)\n",
    "    if len(y) > L:\n",
    "        continue\n",
    "    c[y] += w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e4505-684b-4244-aa9e-6e380ee7fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig = Float.chart({x: b2c(None, x).total_weight() for x in c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec20d2-9545-4a1e-92d6-a504a212d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = Float.chart()\n",
    "for x in c:\n",
    "    ccc[x] = c[x] / ambig[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c58131-7ac7-40f7-9af8-fe6b40b05c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = Float.chart()\n",
    "for x, w in foo.cnf.language(L + 2).items():\n",
    "    if len(x) > L:\n",
    "        continue\n",
    "    cc[''.join(x)] += w\n",
    "# cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248cb64-5bdb-4f86-a70f-a1d4383e0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc.assert_equal(cc, tol=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf30359-1852-4cef-a86f-048dc62dd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.metric(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af56e1c-e4fa-4166-9ba2-ce1f1d82e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.trim(bottomup_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b732ed0-520b-45ba-810b-d0266a7d1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_grammar(tmp, showzero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e2d86-6dfe-45be-87ba-0b6fbfc50c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tmp.agenda().__str__(style_value=lambda k, v: (colors.light.red % v) if v > 1.000001 or v < 0 else v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4baaf-8a5e-4380-81c8-9fe5f5d85bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in c2t.states:\n",
    "#    for (a,b), r, w in c2t.arcs(q):\n",
    "#        print(f'--{a or \"ε\"}:{b or \"ε\"}/{w}-->', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d9420-6e63-4607-b5a9-439238b02140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {x: v for x,v in tmp.agenda().items() if v > 1.001 or v < 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea76dfa-cbc6-4cdd-a413-dda5dd7e9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tmp.N - tmp.agenda(tol=1e-40, maxiter=np.inf).trim().keys()), len(tmp.N), len(tmp.agenda(tol=1e-40).trim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25c7ed-b778-4a0c-819f-0219156e6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.cnf.language(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18614c6-5c17-4467-ae97-f06790f22af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_grammar(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61730b-d679-4404-b062-d3d5bbaa20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = locally_normalize(tmp, tol=1e-20, maxiter=np.inf).trim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a777fe2-77a9-40ff-af4d-d1f02f6ed3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = CFGLM(p.cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ff4b0-5e43-455f-8be8-b42c7d059aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm2.sample(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d26457-e3bf-4f79-8ec0-7d811110982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = (64,65,6485,39305)\n",
    "context = (\n",
    "    64,\n",
    "    65,\n",
    "    6485,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0040787f-6bc0-4ec4-915a-a12aedaaedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_context = tokenizer.decode(context)\n",
    "char_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085cad5-62ac-4385-afba-a848c6583d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for x, w in sorted(lm2.p_next(context).normalize().items(), key=lambda kv: -kv[1]):\n",
    "    df.append((x, (decode[x] if x != EOS else EOS), w))\n",
    "pd.DataFrame(df, columns=['token_id', 'chars', 'prob']).set_index('token_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b30e0-11be-4339-b576-fdd97c9d985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.p_next(char_context).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a035044-4c12-495a-8b70-1a6bda2cbb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3e142ef-2966-4614-aa72-5a998059dc50",
   "metadata": {},
   "source": [
    "## Lexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f8551-e3aa-474b-92d5-3219ad81b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lark_stuff = LarkStuff(\n",
    "    r\"\"\"\n",
    "    start: \"SELECT\" WS STAR WS \"FROM\" WS NAME WS EOS\n",
    "    EOS: \"</s>\"\n",
    "    NAME: /[a-z]+/\n",
    "    STAR: \"*\"\n",
    "    WS: /[ ]/\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1d527-d27a-46e9-8e8e-e2a3da812351",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = lark_stuff.char_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d438bc-5767-444a-a449-571f511575f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo['NAME'].trim().agenda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114f525-ff3b-4736-bc3a-d48ebcff71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo.agenda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2e4dd-81f3-433f-83a0-651f27ca63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = locally_normalize(foo, tol=1e-100).trim()\n",
    "assert len(foo) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fffee2-0852-4aef-a92c-0e6b100be3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79508f80-8c4a-4cc9-8487-10920b285dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = CFGLM(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cde92c-91ea-410a-b002-88b6f383916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = TraceSWOR()\n",
    "for _ in range(15):\n",
    "    print('mass=', trace.root.mass)\n",
    "    with trace:\n",
    "        print(''.join(lm.sample(draw=trace, prob=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e6deb-900c-4dbd-bad4-c51ce910a641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a60e9d-e85b-4759-8653-bcccd72c02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = lark_stuff.convert().renumber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db081114-ac49-4e6d-9c8f-b078966f965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2t = lark_stuff_transducer(lark_stuff, decay=0.0125)\n",
    "len(c2t.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340e2e1-affe-43f2-89d9-6ed0975bdd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8fd795-8971-41aa-8347-883ec12f0623",
   "metadata": {},
   "source": [
    "The `lark` library will only lex it one way because it has a deterministic semantics for prioritized lexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dee626-031a-409c-b523-57810a90b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'SELECT * FROM data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b469dfa-1951-419e-918d-2753befef16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(lark_stuff.lex(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c4399-43c6-44f3-ba0a-9d4c720591ed",
   "metadata": {},
   "source": [
    "However, this string can lex many different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b13795-6d91-4604-847f-76a1cbec7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambig = (\n",
    "    (FST.from_string(x, Float) @ c2t)\n",
    "    .trim.project(1)\n",
    "    .epsremove.trim.to_cfg()\n",
    "    .cnf.language(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d725b7f-f4c0-4cd5-8f0f-61bda50afe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113c156-60a3-48c9-846f-cf9487dc5125",
   "metadata": {},
   "source": [
    "It might be fine to allow ambiguous lexing because very few of the possible lexing options will survive the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb2cbf-8561-4b15-9713-5942a0568883",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in ambig:\n",
    "    v = cfg.prefix_weight(y)  # show all options with a nonzero prefix weight\n",
    "    if v == 0:\n",
    "        continue\n",
    "    print(v, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddeacb6-c2d1-4338-ac43-08f6dfe4dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((FST.from_string('SELECT', Float) @ c2t) @ P.T @ cfg).trim().cnf.language(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efbe84-53c3-4d07-8a32-956036803019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (P.T @ cfg).trim().cnf.language(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2e37c-55cc-485b-b755-3281ad9aaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_t = (c2t.renumber @ cfg).trim()\n",
    "pcfg_t = locally_normalize(cfg_t, tol=1e-100, maxiter=10_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b0d8c-fd5e-4746-a959-c847a3a7bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_t('SELECT * FROM data </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a341822-10fa-4dec-9d48-097e676634a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_t('SELECT * FROM data </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857feb25-f028-43cc-810b-09b905e550df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = CFGLM(pcfg_t.cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658feb1-73eb-4610-8ea7-f5292b698a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(''.join(lm.sample(prob=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be40a1-cc63-454a-a3d5-2ac66baba86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.p_next('SELECT * FROM ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed95fbfe-24fe-42b9-8daa-e07159bd5856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f0582ac-3451-4b7f-bcb0-1fc2cdc8efbe",
   "metadata": {},
   "source": [
    "## BPE Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3113a7ae-ea16-4b18-9612-70b4fdcee7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c = T\n",
    "len(b2c.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822277b4-4f0f-43a2-8783-e6a5831109a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'SELECT * FROM data'\n",
    "b = tokenizer.encode(x)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a439aee-06e4-4e3c-b244-892f29ddc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.decode(bb) for bb in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5ff04-03bb-4965-9f05-8085c90dce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timeit('composition'):\n",
    "    c = FST.from_string(tuple(b), Float) @ b2c\n",
    "about(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35ab22-cc99-4b61-836d-5109ae8934fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.trim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e537195-c06c-4642-8a15-557de5a90f98",
   "metadata": {},
   "source": [
    "We can build this \"transducer\" more efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd29a5c-4b4a-4d65-b3e5-f4375b607fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = bpe2term_approx(tokenizer, tokenizer.encode(x)).epsremove.trim\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42741260-329d-4a9f-aeee-b2655c260144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2df7b26-8065-4ae0-a83d-19d7b5cc436f",
   "metadata": {},
   "source": [
    "## BPE Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e5189-75d8-4d2a-aea7-733608e27baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x = 'SELECT * FROM data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49282e-6174-4ab2-9c52-7be7663ecdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timeit('composition'):\n",
    "    bs = b2c @ FST.from_string(x, Float)\n",
    "with timeit('trim'):\n",
    "    bs.trim\n",
    "about(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf89bc2-a985-44bc-b099-676221f34b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs.trim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e46e7-f348-4790-9f2e-ab3812c61f41",
   "metadata": {},
   "source": [
    "The automaton below describes all the BPE sequences that generate the string `x` and the number below is the total weight of these paths (in the count semiring these are the number of distinct paths):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2c313-c134-488b-9d50-eadd15246f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.trim.project(0).epsremove.trim.total_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cb3c3-6828-4a2d-88d5-d5d5fee491d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.trim.project(0).epsremove.trim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a488f7-91ff-4d0a-a825-c2da8bbccc29",
   "metadata": {},
   "source": [
    "To see all the BPE sequences that generate `x` run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca21894-4a66-4d57-b631-f64f4fc2b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for y in bs.trim.project(0).epsremove.trim.to_cfg().language(10):\n",
    "#    print(tokenizer.decode(y), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9632097d-a97a-4d59-8683-7dd637e3e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29e1dc-bfd3-47a3-be89-fcd79ac1217a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60280fdd-8a22-4764-9e76-97814619a4cb",
   "metadata": {},
   "source": [
    "## The Grafting Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45add727-d4d9-418b-bf92-b7e782f23703",
   "metadata": {},
   "outputs": [],
   "source": [
    "lark_stuff = LarkStuff(\n",
    "    r\"\"\"\n",
    "start: \"SELECT\" WS select_expr WS \"FROM\" WS from_expr [WS \"WHERE\" WS bool_condition] [WS \"GROUP BY\" WS var_list] [WS \"ORDER BY\" WS orderby_expr] WS EOS\n",
    "EOS: \"</s>\"\n",
    "select_expr: STAR | select_list\n",
    "bool_condition: bool_expr | \"(\" bool_condition WS \"AND\" WS bool_condition \")\" | \"(\" bool_condition WS \"OR\" WS bool_condition \")\"\n",
    "bool_expr: var \"=\" value | var \">\" value | var \"<\" value\n",
    "from_expr: \"data\"\n",
    "orderby_expr: var_list WS \"ASC\" | var_list WS \"DESC\"\n",
    "select_list: select_var (\",\" WS select_var)*\n",
    "var_list: var (\",\" WS var)*\n",
    "select_var: var | \"AVG(\" var \")\" | \"MEDIAN(\" var \")\" | \"COUNT(\" var \")\"\n",
    "var: \"age\" | \"gender\" | \"year\" | \"state_color\" | \"zipcode\" | \"vote\" | \"race_ethnicity\"\n",
    "value: NUMBER | \"red\" | \"blue\" | \"white\" | \"black\" | \"latino\" | \"republican\" | \"democrat\" | \"male\" | \"female\"\n",
    "STAR: \"*\"\n",
    "NUMBER: /\\d+/\n",
    "WS: \" \"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "foo = lark_stuff.char_cfg()\n",
    "foo = locally_normalize(foo, tol=1e-100).trim()\n",
    "assert len(foo) > 0\n",
    "lm = CFGLM(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea9156-8c57-4cba-b448-094a29fd05b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94820485-f8eb-48e0-86db-cc0faa3b5271",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(lm.sample(prob=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea67856-e347-4ba0-970c-25bf92b122df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce634f1-f994-4b3f-9390-000649159517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d792b5f-c322-47d7-8190-7937b5967fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_lm = TokenProposal(\n",
    "    guide=lm, llm=MockLLM(V={x for x in decode}, eos=tokenizer.eos_token)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7e87e-cf79-4319-9ecd-5a5f828adee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.p_next('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcecc6-3ea2-4aeb-8ebc-de15472ca0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_lm._prompt = ()\n",
    "bpe_lm._p_next(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0584af6-04a2-46c6-9a85-7c94dfe2e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.p_next('SELECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa025a6-d83a-4ce2-9fa7-9adf08f5621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_lm._p_next(('SELECT',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4720986-8690-49b4-ac18-20539b6a622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = bpe_lm.sample()\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a084d8-151d-46d7-8fe8-bdea49485ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7bbe1-ec3a-4599-a615-e3bb489989d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
